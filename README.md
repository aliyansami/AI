# AI
Goal:
The main goal was to build a project that could detect the images of a given testing data set in order to classify into different classes with high proficiency and maximum accuracy. For this purpose CNN (Convolution Neural Network was used ) since it is one of the leading approaches when it comes to classifying image data.


Working:
It sets the path to the folder containing the test images.It reads the image files from the folder, resizes them to 28x28 pixels, and stores the data set.The image data and labels are converted to numpy arrays and the images are flattened to 1D arrays. The pixel values of the images are normalized using StandardScaler.The balance of the dataset is checked using pandas value_counts function and oversampling is performed using RandomOverSampler from imblearn library.The dataset is split into a training set and a testing set using train_test_split from sklearn.The images and labels are further preprocessed and reshaped to be compatible with the model.
A convolutional neural network (CNN) model is defined using the Keras Sequential API, with convolutional and dense layers. The model is compiled with an optimizer, loss function, and evaluation metrics.
The model is trained on the training data for a specified number of epochs, with a batch size and validation split.The trained model is saved to a file.


The CNN Model Used:

The CNN model architecture consists of several layers that learn and extract features from the input images. The layers used in this project include:

Reshape Layer: Reshapes the input data to match the expected shape for the subsequent convolutional layers.
Convolutional Layers: Apply a set of filters to the input image, capturing various image features through convolutions. These layers help the model detect patterns and local features.
Max Pooling Layers: Reduce the spatial dimensions of the feature maps generated by the convolutional layers, retaining the most important features. This reduces the computational complexity and enhances translation invariance.
Flatten Layer: Flattens the multi-dimensional feature maps into a 1D vector, preparing the data for the fully connected layers.
Dense Layers: Fully connected layers that perform classification based on the learned features. They process the flattened input and apply non-linear transformations to make predictions.
Dropout Layer: Helps prevent overfitting by randomly dropping a fraction of the neurons during training, forcing the model to learn more robust and generalized representations.
Output Layer: The final dense layer with softmax activation produces the probability distribution over the classes.
Compilation and Training: The model is compiled with an optimizer (Adam), a loss function (sparse_categorical_crossentropy), and evaluation metrics (accuracy). It is then trained on the preprocessed training data using the fit() function. The training is performed for a specified number of epochs with a given batch size. Additionally, a validation split is used to evaluate the model's performance on a portion of the training data during training.



Additional Working:
We also used a working GUI in order to create run time images of the digits by the user and classify them into their respective classes. The accuracy of such classification depends on how well defined the image has been drawn by the user. This in fact was quite interesting for all of us since it provided a new sense of challenge to our training model and helped to engage the audience with itself.

